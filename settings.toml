llm_model_families = ["oai_llm_models", "ms_llm_models"]
image_model_families = ["oai_image_models"]

oai_llm_models = ["oai_gpt-3.5-turbo", "oai_gpt-4"]
oai_image_models = ["oai_dall-e-2", "oai_dall-e-3"]

ms_llm_models = ["ms_openai_gpt_35"]

# LLM Models

oai_gpt-3.5-turbo.deployment = "gpt-3.5-turbo"
oai_gpt-3.5-turbo.max_tokens = 4096

oai_gpt-4.deployment = "gpt-4-1106-preview"
oai_gpt-4.max_tokens = 8192

ms_openai_gpt_35.deployment = "test"
ms_openai_gpt_35.max_tokens = 4096
ms_openai_gpt_35.api = "2023-03-15-preview"
ms_openai_gpt_35.proxy = ""

# Image Models

oai_dall-e-2.model = "dall-e-2"
oai_dall-e-2.num_images = 1
oai_dall-e-2.size = "1024x1024"
oai_dall-e-2.quality = "standard"

oai_dall-e-3.model = "dall-e-3"
oai_dall-e-3.num_images = 1
oai_dall-e-3.size = "1024x1024"
oai_dall-e-3.quality = "standard"

# base_url moved to .secrets.toml as it references account-specific information.  
# .secrects.toml needs dynaconf-merge = true for this to work
#ms_openai_gpt_35.base_url = "https://openai.azure.com"

default_llm_model = "oai_gpt-3.5-turbo"
#default_llm_model = "ms_openai_gpt_35"
default_llm_temperature = 0.7
default_persona = "default"

default_image_model = "oai_dall-e-3"

# Using ConversationSummaryBufferMemory - specify model and max_tokens
memory_model = "oai_gpt-3.5-turbo"
memory_model_temperature = 0.1
memory_model_max_tokens = 2048

# in .secrets.toml
# dynaconf_merge = true
# oai_models_api_key = "oai_ai_api_key_goes_here"
# ms_models_api_key = "ms_openai_api_key_goes_here"
